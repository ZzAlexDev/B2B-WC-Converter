"""
–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã
"""

import json
import time
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from datetime import datetime

from src.loaders.xlsx_loader import XLSXLoader
from src.processors.product_builder import ProductBuilder
from src.processors.wc_formatter import WCFormatter
from src.exporters.csv_exporter import CSVExporter
from src.core.models.product import Product
from src.utils.logger import get_logger, log_info, log_error, log_batch_progress


class B2BWCConverter:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ B2B ‚Üí WooCommerce
    """
    
    def __init__(self, config_path: str = "config/settings.json"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
        
        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.logger = get_logger()
        self.config = self._load_config(config_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.loader = XLSXLoader(config_path)
        self.builder = ProductBuilder(self.config)
        self.formatter = WCFormatter(self.config)
        self.exporter = CSVExporter(self.config)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "start_time": None,
            "end_time": None,
            "total_files": 0,
            "total_products": 0,
            "successful_products": 0,
            "failed_products": 0,
            "exported_csv_files": 0
        }
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_path}: {e}")
            return {}
    
    def convert_file(
        self,
        input_file: str,
        output_dir: str = "data/output",
        batch_size: int = None,
        skip_images_download: bool = True,
        save_json_debug: bool = False
    ) -> Dict[str, Any]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ XLSX —Ñ–∞–π–ª–∞
        
        Args:
            input_file: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É XLSX —Ñ–∞–π–ª—É
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            batch_size: –†–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (None = –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            skip_images_download: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            save_json_debug: –°–æ—Ö—Ä–∞–Ω—è—Ç—å JSON –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        """
        self.stats["start_time"] = datetime.now()
        self.stats["total_files"] += 1
        
        self.logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {input_file}")
        
        results = {
            "input_file": input_file,
            "success": False,
            "products_processed": 0,
            "products_successful": 0,
            "products_failed": 0,
            "output_files": [],
            "errors": [],
            "warnings": []
        }
        
        try:
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ XLSX —Ñ–∞–π–ª–∞
            self.logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ XLSX —Ñ–∞–π–ª–∞...")
            load_result = self.loader.process_file(input_file, save_analysis=True)
            
            if not load_result or not load_result.get("is_valid"):
                results["errors"].append("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å XLSX —Ñ–∞–π–ª")
                return results
            
            df = load_result["dataframe"]
            batches = load_result["batches"]
            
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç–æ–≤–∞—Ä–æ–≤, —Ä–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(batches)} –ø–∞—á–µ–∫")
            
            # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—á–µ–∫
            all_products = []
            
            for batch_idx, batch_df in enumerate(batches):
                self.logger.info(f"üî® –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—á–∫–∏ {batch_idx + 1}/{len(batches)}...")
                
                batch_products = self._process_batch(
                    batch_df=batch_df,
                    batch_idx=batch_idx,
                    skip_images_download=skip_images_download
                )
                
                all_products.extend(batch_products)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                processed = len(all_products)
                total = len(df)
                percent = (processed / total) * 100
                self.logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {processed}/{total} ({percent:.1f}%)")
            
            # 3. –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
            successful_products = [p for p in all_products if p is not None]
            failed_count = len(all_products) - len(successful_products)
            
            results["products_processed"] = len(all_products)
            results["products_successful"] = len(successful_products)
            results["products_failed"] = failed_count
            
            if not successful_products:
                results["errors"].append("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞")
                return results
            
            # 4. –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
            self.logger.info("üì§ –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV...")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            input_filename = Path(input_file).stem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_filename = f"wc_import_{input_filename}_{timestamp}.csv"
            csv_path = Path(output_dir) / csv_filename
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º
            export_result = self.exporter.export_products(
                successful_products,
                str(csv_path),
                include_headers=True
            )
            
            if export_result["exported"] > 0:
                results["output_files"].append(str(csv_path))
                results["success"] = True
                
                self.logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {csv_path}")
                self.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {export_result['exported']} —Ç–æ–≤–∞—Ä–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ")
            else:
                results["errors"].append("–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–≤–∞—Ä—ã –≤ CSV")
            
            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if save_json_debug:
                debug_path = Path(output_dir) / f"debug_{input_filename}_{timestamp}.json"
                self._save_debug_data(successful_products, str(debug_path))
                results["output_files"].append(str(debug_path))
                self.logger.info(f"üìã JSON –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {debug_path}")
            
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report_path = Path(output_dir) / f"report_{input_filename}_{timestamp}.json"
            self._save_conversion_report(results, str(report_path))
            results["output_files"].append(str(report_path))
            
            # 7. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.stats["total_products"] += len(all_products)
            self.stats["successful_products"] += len(successful_products)
            self.stats["failed_products"] += failed_count
            self.stats["exported_csv_files"] += 1 if export_result["exported"] > 0 else 0
            
            self.logger.info(f"üéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            
            return results
            
        except Exception as e:
            error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            results["errors"].append(error_msg)
            return results
        
        finally:
            self.stats["end_time"] = datetime.now()
    
    def _process_batch(
        self,
        batch_df,
        batch_idx: int,
        skip_images_download: bool = True
    ) -> List[Optional[Product]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–∞—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤
        
        Args:
            batch_df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞—á–∫–∏
            batch_idx: –ò–Ω–¥–µ–∫—Å –ø–∞—á–∫–∏
            skip_images_download: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ (None –¥–ª—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö)
        """
        batch_products = []
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if skip_images_download and hasattr(self.builder.parsers["images"], "skip_download"):
            self.builder.parsers["images"].skip_download = True
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
        for row_idx, row in batch_df.iterrows():
            global_row_idx = batch_idx * len(batch_df) + row_idx + 1
            
            try:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Å–ª–æ–≤–∞—Ä—å
                row_dict = row.to_dict()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–≤–∞—Ä
                product = self.builder.build_from_row(row_dict, global_row_idx)
                
                batch_products.append(product)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤–Ω—É—Ç—Ä–∏ –ø–∞—á–∫–∏
                if (row_idx + 1) % 10 == 0:
                    self.logger.debug(f"–ü–∞—á–∫–∞ {batch_idx + 1}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {row_idx + 1}/{len(batch_df)} —Å—Ç—Ä–æ–∫")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {global_row_idx}: {e}")
                batch_products.append(None)
                continue
        
        return batch_products
    
    def _save_debug_data(self, products: List[Product], output_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ JSON"""
        try:
            debug_data = {
                "generated_at": datetime.now().isoformat(),
                "total_products": len(products),
                "products": []
            }
            
            for product in products[:10]:  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if product:
                    product_data = {
                        "id": product.id,
                        "name": product.name,
                        "sku": product.sku,
                        "price": product.price,
                        "category": product.category_hierarchy,
                        "brand": product.brand,
                        "wc_fields": product.wc_fields,
                        "main_attributes": product.main_attributes,
                        "has_images": len(product.images_local) > 0,
                        "description_length": len(product.description_final)
                    }
                    debug_data["products"].append(product_data)
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(debug_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def _save_conversion_report(self, results: Dict[str, Any], output_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        try:
            report_data = {
                "conversion_report": {
                    "timestamp": datetime.now().isoformat(),
                    "duration_seconds": (self.stats["end_time"] - self.stats["start_time"]).total_seconds() 
                                       if self.stats["start_time"] and self.stats["end_time"] else 0,

                    "input_file": results.get("input_file", ""),
                    "success": results.get("success", False),
                    "statistics": {
                        "processed": results.get("products_processed", 0),
                        "successful": results.get("products_successful", 0),
                        "failed": results.get("products_failed", 0),
                        "success_rate": (results.get("products_successful", 0) / 
                                       results.get("products_processed", 1) * 100)
                    },
                    "output_files": results.get("output_files", []),
                    "errors": results.get("errors", []),
                    "warnings": results.get("warnings", [])
                },
                "system_stats": {
                    k: (v.isoformat() if isinstance(v, datetime) else v)
                    for k, v in self.get_stats().items()
                }
            }

            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
                
            self.logger.info(f"üìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
    
    def convert_directory(
        self,
        input_dir: str,
        output_dir: str = "data/output",
        file_pattern: str = "*.xlsx"
    ) -> List[Dict[str, Any]]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö XLSX —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        
        Args:
            input_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å XLSX —Ñ–∞–π–ª–∞–º–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            file_pattern: –®–∞–±–ª–æ–Ω –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        """
        self.logger.info(f"üìÅ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {input_dir}")
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
        input_path = Path(input_dir)
        if not input_path.exists():
            self.logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_dir}")
            return []
        
        xlsx_files = list(input_path.glob(file_pattern))
        
        if not xlsx_files:
            self.logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ XLSX —Ñ–∞–π–ª–æ–≤ –≤ {input_dir}")
            return []
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(xlsx_files)}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        all_results = []
        
        for file_idx, xlsx_file in enumerate(xlsx_files, 1):
            self.logger.info(f"üìÑ –§–∞–π–ª {file_idx}/{len(xlsx_files)}: {xlsx_file.name}")
            
            result = self.convert_file(
                input_file=str(xlsx_file),
                output_dir=output_dir,
                skip_images_download=True
            )
            
            all_results.append(result)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–∏—Å—Ç–µ–º—É)
            if file_idx < len(xlsx_files):
                time.sleep(1)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        self._create_summary_report(all_results, output_dir)
        
        return all_results
    
    def _create_summary_report(self, all_results: List[Dict[str, Any]], output_dir: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            summary = {
                "summary_report": {
                    "generated_at": datetime.now().isoformat(),
                    "total_files": len(all_results),
                    "total_processed": sum(r.get("products_processed", 0) for r in all_results),
                    "total_successful": sum(r.get("products_successful", 0) for r in all_results),
                    "total_failed": sum(r.get("products_failed", 0) for r in all_results),
                    "successful_files": sum(1 for r in all_results if r.get("success", False)),
                    "failed_files": sum(1 for r in all_results if not r.get("success", True)),
                    "all_output_files": []
                },
                "file_details": []
            }
            
            for result in all_results:
                summary["file_details"].append({
                    "input_file": result.get("input_file", ""),
                    "success": result.get("success", False),
                    "processed": result.get("products_processed", 0),
                    "successful": result.get("products_successful", 0),
                    "failed": result.get("products_failed", 0),
                    "output_files": result.get("output_files", [])
                })
                
                summary["summary_report"]["all_output_files"].extend(
                    result.get("output_files", [])
                )
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            total_processed = summary["summary_report"]["total_processed"]
            total_successful = summary["summary_report"]["total_successful"]
            
            if total_processed > 0:
                summary["summary_report"]["success_rate"] = (total_successful / total_processed) * 100
            else:
                summary["summary_report"]["success_rate"] = 0
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            report_path = Path(output_dir) / "conversion_summary.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"üìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å
            self.logger.info("=" * 60)
            self.logger.info("üìà –°–í–û–î–ö–ê –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò:")
            self.logger.info(f"   –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {summary['summary_report']['total_files']}")
            self.logger.info(f"   –¢–æ–≤–∞—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed}")
            self.logger.info(f"   –¢–æ–≤–∞—Ä–æ–≤ —É—Å–ø–µ—à–Ω–æ: {total_successful}")
            self.logger.info(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {summary['summary_report']['success_rate']:.1f}%")
            self.logger.info("=" * 60)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞"""
        duration = None
        if self.stats["start_time"] and self.stats["end_time"]:
            duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        
        return {
            **self.stats,
            "duration_seconds": duration,
            "success_rate": (self.stats["successful_products"] / self.stats["total_products"] * 100 
                           if self.stats["total_products"] > 0 else 0)
        }
    
    def reset_stats(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.stats = {
            "start_time": None,
            "end_time": None,
            "total_files": 0,
            "total_products": 0,
            "successful_products": 0,
            "failed_products": 0,
            "exported_csv_files": 0
        }


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def convert_xlsx_to_wc(
    input_file: str,
    output_dir: str = "data/output",
    config_path: str = "config/settings.json"
) -> bool:
    """
    –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è XLSX –≤ WooCommerce CSV
    
    Args:
        input_file: –ü—É—Ç—å –∫ XLSX —Ñ–∞–π–ª—É
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    
    Returns:
        True –µ—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
    """
    converter = B2BWCConverter(config_path)
    result = converter.convert_file(input_file, output_dir)
    return result.get("success", False)


def convert_directory_to_wc(
    input_dir: str,
    output_dir: str = "data/output",
    config_path: str = "config/settings.json",
    file_pattern: str = "*.xlsx"
) -> List[Dict[str, Any]]:
    """
    –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö XLSX —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    
    Args:
        input_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å XLSX —Ñ–∞–π–ª–∞–º–∏
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        file_pattern: –®–∞–±–ª–æ–Ω –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    """
    converter = B2BWCConverter(config_path)
    return converter.convert_directory(input_dir, output_dir, file_pattern)